{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving Deep Neural Network through Django\n",
    "\n",
    "This notebook is the simple neural network we build for this workshop. It comprises of using specified parameters to classify mobile phones in price range.\n",
    "\n",
    "The dataset for this work is gotten from https://www.kaggle.com/iabhishekofficial/mobile-price-classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"dataset/train.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "0               842     0          2.2         0   1       0           7   \n",
       "1              1021     1          0.5         1   0       1          53   \n",
       "2               563     1          0.5         1   2       1          41   \n",
       "3               615     1          2.5         0   0       0          10   \n",
       "4              1821     1          1.2         0  13       1          44   \n",
       "5              1859     0          0.5         1   3       0          22   \n",
       "6              1821     0          1.7         0   4       1          10   \n",
       "7              1954     0          0.5         1   0       0          24   \n",
       "8              1445     1          0.5         0   0       0          53   \n",
       "9               509     1          0.6         1   2       1           9   \n",
       "10              769     1          2.9         1   0       0           9   \n",
       "11             1520     1          2.2         0   5       1          33   \n",
       "12             1815     0          2.8         0   2       0          33   \n",
       "13              803     1          2.1         0   7       0          17   \n",
       "14             1866     0          0.5         0  13       1          52   \n",
       "15              775     0          1.0         0   3       0          46   \n",
       "16              838     0          0.5         0   1       1          13   \n",
       "17              595     0          0.9         1   7       1          23   \n",
       "18             1131     1          0.5         1  11       0          49   \n",
       "19              682     1          0.5         0   4       0          19   \n",
       "20              772     0          1.1         1  12       0          39   \n",
       "21             1709     1          2.1         0   1       0          13   \n",
       "22             1949     0          2.6         1   4       0          47   \n",
       "23             1602     1          2.8         1   4       1          38   \n",
       "24              503     0          1.2         1   5       1           8   \n",
       "25              961     1          1.4         1   0       1          57   \n",
       "26              519     1          1.6         1   7       1          51   \n",
       "27              956     0          0.5         0   1       1          41   \n",
       "28             1453     0          1.6         1  12       1          52   \n",
       "29              851     0          0.5         0   3       0          21   \n",
       "...             ...   ...          ...       ...  ..     ...         ...   \n",
       "1970           1913     1          1.8         0   0       0          29   \n",
       "1971            538     0          1.1         1   0       1          25   \n",
       "1972           1191     0          0.8         0   6       1          46   \n",
       "1973            816     0          3.0         1   2       0           9   \n",
       "1974            915     1          0.5         1   9       1          33   \n",
       "1975           1157     1          0.8         0   7       0          27   \n",
       "1976           1201     1          0.5         0   2       0          10   \n",
       "1977           1379     0          1.1         1   1       1          18   \n",
       "1978           1483     1          2.2         0   3       1          53   \n",
       "1979           1614     0          1.2         0   1       1           9   \n",
       "1980            930     1          1.0         1   4       1           4   \n",
       "1981           1454     0          2.6         0   8       0           6   \n",
       "1982           1784     0          1.6         0   4       0          41   \n",
       "1983           1262     0          1.8         1  12       0          34   \n",
       "1984            797     0          2.2         1   0       0          37   \n",
       "1985           1829     1          2.1         0   8       0          59   \n",
       "1986           1139     1          0.9         1   6       1          58   \n",
       "1987            618     1          1.0         0   9       1          13   \n",
       "1988           1547     1          2.9         0   2       0          57   \n",
       "1989            586     0          2.8         0   2       0          15   \n",
       "1990           1617     1          2.4         0   8       1          36   \n",
       "1991           1882     0          2.0         0  11       1          44   \n",
       "1992            674     1          2.9         1   1       0          21   \n",
       "1993           1467     1          0.5         0   0       0          18   \n",
       "1994            858     0          2.2         0   1       0          50   \n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0       0.6        188        2  ...         20       756  2549     9     7   \n",
       "1       0.7        136        3  ...        905      1988  2631    17     3   \n",
       "2       0.9        145        5  ...       1263      1716  2603    11     2   \n",
       "3       0.8        131        6  ...       1216      1786  2769    16     8   \n",
       "4       0.6        141        2  ...       1208      1212  1411     8     2   \n",
       "5       0.7        164        1  ...       1004      1654  1067    17     1   \n",
       "6       0.8        139        8  ...        381      1018  3220    13     8   \n",
       "7       0.8        187        4  ...        512      1149   700    16     3   \n",
       "8       0.7        174        7  ...        386       836  1099    17     1   \n",
       "9       0.1         93        5  ...       1137      1224   513    19    10   \n",
       "10      0.1        182        5  ...        248       874  3946     5     2   \n",
       "11      0.5        177        8  ...        151      1005  3826    14     9   \n",
       "12      0.6        159        4  ...        607       748  1482    18     0   \n",
       "13      1.0        198        4  ...        344      1440  2680     7     1   \n",
       "14      0.7        185        1  ...        356       563   373    14     9   \n",
       "15      0.7        159        2  ...        862      1864   568    17    15   \n",
       "16      0.1        196        8  ...        984      1850  3554    10     9   \n",
       "17      0.1        121        3  ...        441       810  3752    10     2   \n",
       "18      0.6        101        5  ...        658       878  1835    19    13   \n",
       "19      1.0        121        4  ...        902      1064  2337    11     1   \n",
       "20      0.8         81        7  ...       1314      1854  2819    17    15   \n",
       "21      1.0        156        2  ...        974      1385  3283    17     1   \n",
       "22      0.3        199        4  ...        407       822  1433    11     5   \n",
       "23      0.7        114        3  ...        466       788  1037     8     7   \n",
       "24      0.4        111        3  ...        201      1245  2583    11     0   \n",
       "25      0.6        114        8  ...        291      1434  2782    18     9   \n",
       "26      0.3        132        4  ...        550       645  3763    16     1   \n",
       "27      1.0        143        7  ...        511      1075  3286    17     8   \n",
       "28      0.3         96        2  ...        187      1311  2373    10     1   \n",
       "29      0.4        200        5  ...       1171      1263   478    12     7   \n",
       "...     ...        ...      ...  ...        ...       ...   ...   ...   ...   \n",
       "1970    0.6        111        5  ...        675       742  2023    17    13   \n",
       "1971    0.3        163        7  ...        455       537  2215     9     3   \n",
       "1972    0.8         89        6  ...         42       807   824    19    18   \n",
       "1973    0.1        117        1  ...       1196      1651  3851    10     3   \n",
       "1974    0.3        199        2  ...        503       986  2156     7     3   \n",
       "1975    0.1         88        8  ...       1694      1798  2885     8     4   \n",
       "1976    1.0         99        7  ...        306       558   495    15     6   \n",
       "1977    0.2        129        2  ...        838       885  2358    10     5   \n",
       "1978    0.7        169        5  ...        291       651  1744     6     3   \n",
       "1979    0.1        161        3  ...        173      1219  1832    15     8   \n",
       "1980    0.9        144        8  ...       1017      1289  2016    13    10   \n",
       "1981    0.4        199        3  ...        698      1018  1300    10     0   \n",
       "1982    0.4        164        6  ...        610      1437  2313    14     1   \n",
       "1983    0.1        149        5  ...        223       737  3248    13     3   \n",
       "1984    0.9        144        7  ...        206      1167  2216     9     5   \n",
       "1985    0.1         91        5  ...       1457      1919  3142    16     6   \n",
       "1986    0.5        161        2  ...        742       999  1850     9     4   \n",
       "1987    0.1         80        4  ...        591       724  1424    15    12   \n",
       "1988    0.4        114        1  ...        347       957  1620     9     2   \n",
       "1989    0.2         83        3  ...        241       854  2592    12     8   \n",
       "1990    0.8         85        1  ...        743      1426   296     5     3   \n",
       "1991    0.8        113        8  ...          4       743  3579    19     8   \n",
       "1992    0.2        198        3  ...        576      1809  1180     6     3   \n",
       "1993    0.6        122        5  ...        888      1099  3962    15    11   \n",
       "1994    0.1         84        1  ...        528      1416  3978    17    16   \n",
       "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
       "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
       "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
       "1998    0.1        145        5  ...        336       670   869    18    10   \n",
       "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0            19        0             0     1            1  \n",
       "1             7        1             1     0            2  \n",
       "2             9        1             1     0            2  \n",
       "3            11        1             0     0            2  \n",
       "4            15        1             1     0            1  \n",
       "5            10        1             0     0            1  \n",
       "6            18        1             0     1            3  \n",
       "7             5        1             1     1            0  \n",
       "8            20        1             0     0            0  \n",
       "9            12        1             0     0            0  \n",
       "10            7        0             0     0            3  \n",
       "11           13        1             1     1            3  \n",
       "12            2        1             0     0            1  \n",
       "13            4        1             0     1            2  \n",
       "14            3        1             0     1            0  \n",
       "15           11        1             1     1            0  \n",
       "16           19        1             0     1            3  \n",
       "17           18        1             1     0            3  \n",
       "18           16        1             1     0            1  \n",
       "19           18        0             1     1            1  \n",
       "20            3        1             1     0            3  \n",
       "21           15        1             0     0            3  \n",
       "22           20        0             0     1            1  \n",
       "23           20        1             0     0            0  \n",
       "24           12        1             0     0            1  \n",
       "25            7        1             1     1            2  \n",
       "26            4        1             0     1            3  \n",
       "27           12        1             1     0            3  \n",
       "28           10        1             1     1            2  \n",
       "29           10        1             0     1            0  \n",
       "...         ...      ...           ...   ...          ...  \n",
       "1970          8        1             1     0            2  \n",
       "1971         17        1             1     1            1  \n",
       "1972          7        1             0     0            0  \n",
       "1973         14        1             0     1            3  \n",
       "1974         13        1             1     0            1  \n",
       "1975          2        1             0     1            3  \n",
       "1976         14        1             1     1            0  \n",
       "1977         15        1             1     0            2  \n",
       "1978         10        1             0     0            1  \n",
       "1979         11        1             0     0            1  \n",
       "1980         16        1             1     1            1  \n",
       "1981          2        0             0     1            1  \n",
       "1982         11        0             1     0            2  \n",
       "1983          4        0             1     1            2  \n",
       "1984          6        1             0     0            1  \n",
       "1985          5        1             1     1            3  \n",
       "1986          8        1             0     0            1  \n",
       "1987          7        1             1     0            0  \n",
       "1988         19        0             1     1            1  \n",
       "1989          3        0             0     0            1  \n",
       "1990          7        1             0     0            0  \n",
       "1991         20        1             1     0            3  \n",
       "1992          4        1             1     1            0  \n",
       "1993          5        1             1     1            3  \n",
       "1994          3        1             1     0            3  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[2000 rows x 21 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.420e+02 0.000e+00 2.200e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [1.021e+03 1.000e+00 5.000e-01 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [5.630e+02 1.000e+00 5.000e-01 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " ...\n",
      " [1.911e+03 0.000e+00 9.000e-01 ... 1.000e+00 1.000e+00 0.000e+00]\n",
      " [1.512e+03 0.000e+00 9.000e-01 ... 1.000e+00 1.000e+00 1.000e+00]\n",
      " [5.100e+02 1.000e+00 2.000e+00 ... 1.000e+00 1.000e+00 1.000e+00]]\n",
      "\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [3]\n",
      " [0]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "#convert pandas Dataframe to numpy array\n",
    "\n",
    "X = data.iloc[:,:20].values\n",
    "y = data.iloc[:,20:21].values\n",
    "\n",
    "\n",
    "\n",
    "print(X)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90259726 -0.9900495   0.83077942 ... -1.78686097 -1.00601811\n",
      "   0.98609664]\n",
      " [-0.49513857  1.0100505  -1.2530642  ...  0.55964063  0.99401789\n",
      "  -1.01409939]\n",
      " [-1.5376865   1.0100505  -1.2530642  ...  0.55964063  0.99401789\n",
      "  -1.01409939]\n",
      " ...\n",
      " [ 1.53077336 -0.9900495  -0.76274805 ...  0.55964063  0.99401789\n",
      "  -1.01409939]\n",
      " [ 0.62252745 -0.9900495  -0.76274805 ...  0.55964063  0.99401789\n",
      "   0.98609664]\n",
      " [-1.65833069  1.0100505   0.58562134 ...  0.55964063  0.99401789\n",
      "   0.98609664]]\n",
      "\n",
      "[[1]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [3]\n",
      " [0]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "print(X)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       1\n",
       "5       1\n",
       "6       3\n",
       "7       0\n",
       "8       0\n",
       "9       0\n",
       "10      3\n",
       "11      3\n",
       "12      1\n",
       "13      2\n",
       "14      0\n",
       "15      0\n",
       "16      3\n",
       "17      3\n",
       "18      1\n",
       "19      1\n",
       "20      3\n",
       "21      3\n",
       "22      1\n",
       "23      0\n",
       "24      1\n",
       "25      2\n",
       "26      3\n",
       "27      3\n",
       "28      2\n",
       "29      0\n",
       "       ..\n",
       "1970    2\n",
       "1971    1\n",
       "1972    0\n",
       "1973    3\n",
       "1974    1\n",
       "1975    3\n",
       "1976    0\n",
       "1977    2\n",
       "1978    1\n",
       "1979    1\n",
       "1980    1\n",
       "1981    1\n",
       "1982    2\n",
       "1983    2\n",
       "1984    1\n",
       "1985    3\n",
       "1986    1\n",
       "1987    0\n",
       "1988    1\n",
       "1989    1\n",
       "1990    0\n",
       "1991    3\n",
       "1992    0\n",
       "1993    3\n",
       "1994    3\n",
       "1995    0\n",
       "1996    2\n",
       "1997    3\n",
       "1998    0\n",
       "1999    3\n",
       "Name: price_range, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perform one hot encoding of output class\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "Y = data['price_range']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashpot\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(y).toarray()\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split test and train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Build the Neural Network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ashpot\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Ashpot\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 0s 172us/step - loss: 1.4514 - accuracy: 0.2861\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 1.3677 - accuracy: 0.3156\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 1.3069 - accuracy: 0.3567\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 1.2480 - accuracy: 0.4194\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 0s 39us/step - loss: 1.1818 - accuracy: 0.4744\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 0s 33us/step - loss: 1.1065 - accuracy: 0.5372\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 1.0265 - accuracy: 0.5700\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.9462 - accuracy: 0.6178\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.8699 - accuracy: 0.6461\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.8005 - accuracy: 0.6761\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.7368 - accuracy: 0.7122\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 0s 38us/step - loss: 0.6810 - accuracy: 0.7417\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 0s 48us/step - loss: 0.6312 - accuracy: 0.7628\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 0s 35us/step - loss: 0.5883 - accuracy: 0.7894\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.5481 - accuracy: 0.8172\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.5141 - accuracy: 0.8350\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.4842 - accuracy: 0.8400\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.4557 - accuracy: 0.8478\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.4302 - accuracy: 0.8611\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.4061 - accuracy: 0.8683\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.3847 - accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.3657 - accuracy: 0.8850\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.3478 - accuracy: 0.8833\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.3308 - accuracy: 0.8978\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 0s 33us/step - loss: 0.3159 - accuracy: 0.8994\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.3022 - accuracy: 0.9044\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.2889 - accuracy: 0.9089\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.2765 - accuracy: 0.9128\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.2685 - accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.2556 - accuracy: 0.9200\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.2454 - accuracy: 0.9222\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.2360 - accuracy: 0.9267\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 0s 43us/step - loss: 0.2273 - accuracy: 0.9300\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 0s 45us/step - loss: 0.2192 - accuracy: 0.9333\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.2111 - accuracy: 0.9378\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.2032 - accuracy: 0.9389\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.1976 - accuracy: 0.9439\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.1902 - accuracy: 0.9467\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.1845 - accuracy: 0.9478\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.1791 - accuracy: 0.9522\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.1739 - accuracy: 0.9478\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.1678 - accuracy: 0.9533\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.1637 - accuracy: 0.9544\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 0s 46us/step - loss: 0.1580 - accuracy: 0.9572\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 0s 47us/step - loss: 0.1542 - accuracy: 0.9589\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 0s 39us/step - loss: 0.1484 - accuracy: 0.9622\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 0s 37us/step - loss: 0.1441 - accuracy: 0.9606\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 0s 40us/step - loss: 0.1407 - accuracy: 0.9644\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 0s 39us/step - loss: 0.1366 - accuracy: 0.9628\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 0s 44us/step - loss: 0.1327 - accuracy: 0.9650\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 0s 56us/step - loss: 0.1287 - accuracy: 0.9672\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 0s 38us/step - loss: 0.1259 - accuracy: 0.9661\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 0s 40us/step - loss: 0.1225 - accuracy: 0.9683\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 0s 33us/step - loss: 0.1198 - accuracy: 0.9706\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 0s 37us/step - loss: 0.1166 - accuracy: 0.9717\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.1144 - accuracy: 0.9689\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 0s 33us/step - loss: 0.1106 - accuracy: 0.9744\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 0s 32us/step - loss: 0.1082 - accuracy: 0.9744 0s - loss: 0.1079 - accuracy: 0.97\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 0s 35us/step - loss: 0.1060 - accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 0s 37us/step - loss: 0.1036 - accuracy: 0.9739\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.1029 - accuracy: 0.9733\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.0991 - accuracy: 0.9750\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0964 - accuracy: 0.9750\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.0950 - accuracy: 0.9739\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 0s 33us/step - loss: 0.0936 - accuracy: 0.9794\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 0s 51us/step - loss: 0.0906 - accuracy: 0.9778\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 0s 52us/step - loss: 0.0884 - accuracy: 0.9811\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 0s 38us/step - loss: 0.0862 - accuracy: 0.9811\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0858 - accuracy: 0.9800\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0840 - accuracy: 0.9817\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0818 - accuracy: 0.9811\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 0s 32us/step - loss: 0.0811 - accuracy: 0.9828\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0787 - accuracy: 0.9833\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0773 - accuracy: 0.9844\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 0s 29us/step - loss: 0.0779 - accuracy: 0.9811\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 0s 41us/step - loss: 0.0750 - accuracy: 0.9861\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 0.0732 - accuracy: 0.9833\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0724 - accuracy: 0.9850\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0716 - accuracy: 0.9856\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0693 - accuracy: 0.9872\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0684 - accuracy: 0.9856\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0667 - accuracy: 0.9872\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0657 - accuracy: 0.9872\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0648 - accuracy: 0.9883\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 0s 43us/step - loss: 0.0641 - accuracy: 0.9856\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 0s 43us/step - loss: 0.0626 - accuracy: 0.9878\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 0s 40us/step - loss: 0.0629 - accuracy: 0.9872\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.0613 - accuracy: 0.9883\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.0608 - accuracy: 0.9867\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.0594 - accuracy: 0.9861\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0578 - accuracy: 0.9878\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0567 - accuracy: 0.9900\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0560 - accuracy: 0.9894\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0583 - accuracy: 0.9883\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0548 - accuracy: 0.9889\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0535 - accuracy: 0.9906\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 0s 28us/step - loss: 0.0531 - accuracy: 0.9894\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0515 - accuracy: 0.9889\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0527 - accuracy: 0.9889\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0522 - accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=20, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "result = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 3, 2, 3, 1, 0, 1, 1, 0, 3, 2, 3, 1, 2, 2, 3, 3, 2, 1, 2, 0, 3, 1, 2, 2, 3, 3, 3, 0, 1, 0, 2, 1, 1, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 1, 0, 2, 3, 2, 2, 2, 0, 3, 0, 2, 2, 3, 2, 1, 2, 3, 0, 1, 0, 2, 1, 3, 1, 0, 2, 3, 0, 0, 2, 1, 1, 1, 2, 2, 2, 0, 1, 3, 0, 2, 2, 2, 0, 1, 1, 0, 2, 0, 0, 0, 0, 3, 2, 2, 3, 0, 2, 3, 3, 0, 3, 3, 0, 1, 3, 3, 2, 0, 3, 3, 1, 0, 2, 3, 0, 1, 1, 2, 0, 2, 2, 2, 0, 0, 1, 0, 3, 1, 1, 3, 1, 2, 2, 3, 0, 0, 2, 0, 0, 3, 0, 2, 0, 0, 2, 2, 1, 0, 2, 2, 3, 3, 1, 2, 0, 0, 1, 0, 2, 2, 2, 0, 2, 3, 2, 1, 2, 1, 0, 2, 3, 2, 2, 3, 1, 3, 2, 1, 3, 3, 3, 3, 0, 0, 0, 3, 0, 0, 3, 1, 3, 3, 0, 1]\n",
      "\n",
      "[0, 3, 3, 2, 3, 0, 0, 1, 1, 0, 3, 3, 3, 1, 2, 2, 3, 3, 2, 1, 2, 1, 3, 1, 2, 2, 3, 3, 3, 0, 1, 0, 2, 1, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 1, 0, 2, 3, 2, 2, 2, 0, 3, 0, 2, 2, 3, 2, 1, 2, 3, 0, 1, 1, 2, 1, 3, 0, 0, 2, 3, 0, 0, 2, 1, 1, 1, 2, 3, 2, 0, 1, 3, 0, 2, 2, 2, 0, 1, 1, 0, 2, 0, 0, 0, 1, 3, 2, 3, 3, 0, 1, 3, 3, 0, 3, 3, 0, 1, 3, 3, 2, 1, 3, 3, 1, 0, 2, 3, 0, 1, 1, 2, 0, 2, 2, 2, 0, 0, 1, 0, 3, 1, 1, 3, 1, 2, 2, 3, 0, 0, 2, 0, 0, 3, 0, 2, 0, 0, 2, 2, 1, 0, 2, 2, 3, 3, 1, 2, 0, 1, 1, 0, 2, 2, 2, 0, 2, 3, 2, 1, 2, 1, 0, 2, 3, 2, 2, 3, 1, 2, 2, 1, 3, 3, 3, 3, 0, 0, 0, 3, 0, 0, 3, 1, 3, 3, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Convert predictions back to labels\n",
    "\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "    \n",
    "\n",
    "    \n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))\n",
    "    \n",
    "print(pred)\n",
    "print()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing both result shows the accuracy of our neural network\n",
    "\n",
    "Nevetheless, let's use accuracy score to test our model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "a = accuracy_score(pred, test)\n",
    "print('Accuracy =', a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save(\"./saved_model/phone_price_classifier_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What we could next\n",
    "\n",
    "We could go ahead and plot a graph to show the training and validation accuracy, but for this we will need to redo our code and provide validation data for our neural network. But we will skip all that for this workshop as it doesn't necessarily impact on the performance of our model. \n",
    "\n",
    "So let's go ahead and deploy this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
